{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import pi\n",
    "from pyquil.api import get_qc\n",
    "from pyquil.api._devices import get_lattice\n",
    "from pyquil import Program\n",
    "from pyquil.gates import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify lattice name and show any stored specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lattice_name = 'Aspen-1-5Q-B'\n",
    "lattice_name = '9q-square-noisy-qvm'\n",
    "# lattice = get_lattice(lattice_name)\n",
    "# stored_specs = lattice.get_specs()\n",
    "# print(stored_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create qc object, get qubits, and display the topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BE SURE TO SET as_qvm TRUE or FALSE as desired!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "qc = get_qc(lattice_name, as_qvm=True, noisy=True)\n",
    "qubits = qc.qubits()\n",
    "print(qubits)\n",
    "graph = qc.qubit_topology()\n",
    "nx.draw_networkx(graph, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Reset Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forest_benchmarking.readout import estimate_joint_reset_confusion\n",
    "single_qubit_reset_cms = estimate_joint_reset_confusion(qc, qubits, num_trials = 10, joint_group_size = 1,\n",
    "                                   use_active_reset = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix, Avg Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(single_qubit_reset_cms)\n",
    "print([np.round(np.sum(cm, axis=0)[0]/2, 3) for cm in single_qubit_reset_cms.values()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readout Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forest_benchmarking.readout import estimate_joint_confusion_in_set, marginalize_confusion_matrix\n",
    "single_qubit_cms = estimate_joint_confusion_in_set(qc, qubits, num_shots=5000, joint_group_size=1,\n",
    "                                    use_param_program=True, use_active_reset=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix, Avg Fidelity, Asymmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(single_qubit_cms)\n",
    "print([np.round(np.trace(cm)/2, 3) for cm in single_qubit_cms.values()])\n",
    "from forest_benchmarking.utils import sigma_z\n",
    "print([np.round(np.trace(sigma_z @ cm)/2, 3) for cm in single_qubit_cms.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simultaneous Confusion Matrix (pairwise; can try len(qubits) but may be too slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_cms = estimate_joint_confusion_in_set(qc, qubits, num_shots=1000, joint_group_size=2,\n",
    "                                    use_param_program=True, use_active_reset=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Look for Significant Correlated Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marginal_absolute_tolerance = .02 # determines acceptable level of correlation\n",
    "\n",
    "for qubit_pair, pair_cm in pairwise_cms.items():\n",
    "    marginal_one_qs = [(qubit, marginalize_confusion_matrix(pair_cm, qubit_pair, [qubit])) for qubit in qubit_pair]\n",
    "    for qubit, marginal_cm in marginal_one_qs:\n",
    "        if not np.allclose(single_qubit_cms[(qubit,)], marginal_cm, atol=marginal_absolute_tolerance):\n",
    "            print(\"Q\" + str(qubit) + \" readout is different when measuring pair\", qubit_pair)\n",
    "            \n",
    "joint_absolute_tolerance = .03\n",
    "for qubit_pair, pair_cm in pairwise_cms.items():\n",
    "    joint_single_q_cm = np.kron(single_qubit_cms[(qubit_pair[0],)], single_qubit_cms[(qubit_pair[1],)])\n",
    "    if not np.allclose(joint_single_q_cm, pair_cm, atol=joint_absolute_tolerance):\n",
    "        print(qubit_pair, \"exhibits correlated readout error\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T1/T2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither estimation of T1 or T2 will work on a QVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forest_benchmarking.qubit_spectroscopy import run_t1, exponential_decay_curve, fit_to_exponential_decay_curve\n",
    "MICROSECOND = 1e-6\n",
    "def get_T1s_from_data_fit(df, show_plot: bool = False,\n",
    "                                                  filename: str = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Plot T1 experimental data and fitted exponential decay curve.\n",
    "\n",
    "    :param df: Experimental results to plot and fit exponential decay curve to.\n",
    "    :return: list of estimated t1s in microseconds\n",
    "    \"\"\"\n",
    "    t1s = np.array([])\n",
    "    for q in df['qubit'].unique():\n",
    "        df2 = df[df['qubit'] == q].sort_values('time')\n",
    "        x_data = df2['time']\n",
    "        y_data = df2['avg']\n",
    "\n",
    "        plt.plot(x_data, y_data, 'o-', label=f\"QC{q} T1 data\")\n",
    "\n",
    "        try:\n",
    "            fit_params, fit_params_errs = fit_to_exponential_decay_curve(x_data, y_data)\n",
    "        except RuntimeError:\n",
    "            print(f\"Could not fit to experimental data for QC{q}\")\n",
    "            t1s = np.append(t1s,[np.nan])\n",
    "        else:\n",
    "            plt.plot(x_data, exponential_decay_curve(x_data, *fit_params),\n",
    "                     label=f\"QC{q} fit: T1={fit_params[1] / MICROSECOND:.2f}us\")\n",
    "            t1s = np.append(t1s,[fit_params[1]/MICROSECOND])\n",
    "\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Excited state visibility\")\n",
    "    plt.title(\"T1 decay\")\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    if filename is not None:\n",
    "        plt.savefig(filename)\n",
    "        \n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "        \n",
    "    return t1s\n",
    "    \n",
    "t1_df = run_t1(qc, qubits, stop_time = 60*MICROSECOND, n_shots = 1000, num_points = 15)\n",
    "t1s = get_T1s_from_data_fit(t1_df)\n",
    "print(\"T1s in microseconds:\", np.round(t1s,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $T_2^*$ Ramsey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forest_benchmarking.qubit_spectroscopy import run_t2, exponentially_decaying_sinusoidal_curve, fit_to_exponentially_decaying_sinusoidal_curve\n",
    "MHZ = 1e6\n",
    "MICROSECOND = 1e-6\n",
    "from typing import List\n",
    "def get_T2s_from_data_fit(df, show_plot: bool = False, filename: str = None,\n",
    "                                                detuning: float = 5e6) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Plot T2 experimental data and fitted exponential decay curve.\n",
    "\n",
    "    :param df: Experimental results to plot and fit exponential decay curve to.\n",
    "    :param detuning: Detuning frequency used in experiment creation.\n",
    "    :return: list of estimated t2s\n",
    "    \"\"\"\n",
    "    t2s=np.array([])\n",
    "    detunings=np.array([])\n",
    "    for q in df['qubit'].unique():\n",
    "        df2 = df[df['qubit'] == q].sort_values('time')\n",
    "        x_data = df2['time']\n",
    "        y_data = df2['avg']\n",
    "\n",
    "        plt.plot(x_data, y_data, 'o-', label=f\"QC{q} T2 data\")\n",
    "\n",
    "        try:\n",
    "            fit_params, fit_params_errs = fit_to_exponentially_decaying_sinusoidal_curve(x_data,\n",
    "                                                                                         y_data,\n",
    "                                                                                         detuning)\n",
    "        except RuntimeError:\n",
    "            print(f\"Could not fit to experimental data for QC {q}\")\n",
    "            t2s = np.append(t2s,[np.nan])\n",
    "            detunings = np.append(detunings, [np.nan])\n",
    "        else:\n",
    "            plt.plot(x_data, exponentially_decaying_sinusoidal_curve(x_data, *fit_params),\n",
    "                     label=f\"QC{q} fit: freq={fit_params[2] / MHZ:.2f}MHz, \"\n",
    "                           f\"T2={fit_params[1] / MICROSECOND:.2f}us\")\n",
    "            t2s = np.append(t2s,[fit_params[1]/MICROSECOND])\n",
    "            detunings = np.append(detunings, fit_params[2] / MHZ)\n",
    "            \n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Excited state visibility\")\n",
    "    plt.title(\"T2 Ramsey decay\")\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    if filename is not None:\n",
    "        plt.savefig(filename)\n",
    "\n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "        \n",
    "    return t2s, detunings\n",
    "    \n",
    "t2_df,detuning_used = run_t2(qc, qubits, stop_time = 10*MICROSECOND, n_shots = 1000, num_points = 50)\n",
    "t2s, detunings = get_T2s_from_data_fit(t2_df, show_plot=True, detuning=detuning_used)\n",
    "print(\"T2s in microseconds:\", np.round(t2s,1))\n",
    "print(\"Detunings in MHz:\", np.round(detunings,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Qubit Gate Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyquil.api import get_benchmarker\n",
    "from forest_benchmarking.rb import (add_sequences_to_dataframe,\n",
    "                            add_survivals,\n",
    "                            generate_simultaneous_rb_sequence,\n",
    "                            rb_dataframe,\n",
    "                            run_rb_measurement,\n",
    "                            survivals_by_qubits,\n",
    "                           fit_standard_rb)\n",
    "from forest_benchmarking.analysis.fitting import make_figure\n",
    "bm = get_benchmarker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate 1q fidelity separately "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separate_1q_dfs = []\n",
    "depths_1q, survivals_1q, survival_errs_1q = {}, {}, {}\n",
    "separate_1q_rb_decays = []\n",
    "\n",
    "for qubit in qubits:\n",
    "    df = rb_dataframe(rb_type=\"std-1q\",\n",
    "                  subgraph=[(qubit,)],\n",
    "                  depths=3 * 2 ** np.arange(4, dtype=np.uint8),\n",
    "                  num_sequences=50)\n",
    "    df = add_sequences_to_dataframe(df, bm)\n",
    "    df = run_rb_measurement(df, qc, num_trials=500)\n",
    "    df = add_survivals(df)\n",
    "    separate_1q_dfs.append(df)\n",
    "    \n",
    "    depths_1q[qubit], survivals_1q[qubit], survival_errs_1q[qubit] = survivals_by_qubits(df, (qubit,)) \n",
    "    fit = fit_standard_rb(depths_1q[qubit], survivals_1q[qubit], weights=1/survival_errs_1q[qubit])\n",
    "    separate_1q_rb_decays.append(fit.params['decay'].value)\n",
    "    \n",
    "    fig, axs = make_figure(fit, xlabel=\"Sequence Length [Cliffords]\", ylabel=\"Survival Probability\")\n",
    "    \n",
    "print(separate_1q_rb_decays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate simultaneous 1q fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separate_1q_dfs = []\n",
    "depths_1q, survivals_1q, survival_errs_1q = {}, {}, {}\n",
    "simult_1q_rb_decays = []\n",
    "\n",
    "simult_1q_df = rb_dataframe(rb_type=\"sim-1q\",\n",
    "                  subgraph=[(qubit,) for qubit in qubits],\n",
    "                  depths=3 * 2 ** np.arange(4, dtype=np.uint8),\n",
    "                  num_sequences=50)\n",
    "simult_1q_df = add_sequences_to_dataframe(simult_1q_df, bm)\n",
    "simult_1q_df = run_rb_measurement(simult_1q_df, qc, num_trials=500)\n",
    "simult_1q_df = add_survivals(simult_1q_df)\n",
    "\n",
    "for qubit in qubits:\n",
    "    depths, survivals, survival_errs = {}, {}, {}\n",
    "    depths[qubit], survivals[qubit], survival_errs[qubit] = survivals_by_qubits(simult_1q_df, (qubit,))\n",
    "    fit = fit_standard_rb(depths[qubit], survivals[qubit], weights=1/survival_errs[qubit])\n",
    "    simult_1q_rb_decays.append(fit.params['decay'].value)\n",
    "    \n",
    "    fig, axs = make_figure(fit, xlabel=\"Sequence Length [Cliffords]\", ylabel=\"Survival Probability\")\n",
    "    \n",
    "print(simult_1q_rb_decays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for qubit, (simult, sep) in zip(qubits, zip(simult_1q_rb_decays, separate_1q_rb_decays)):\n",
    "    if not np.allclose(simult, sep, atol = .05):\n",
    "        print(\"qubit \" + str(qubit) + \" may be suffering from significant 1q cross-talk.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CZ Fidelity (SLOW on qvm. Set variance as desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forest_benchmarking.dfe import generate_process_dfe_experiment, acquire_dfe_data, direct_fidelity_estimate\n",
    "\n",
    "desired_variance = .1\n",
    "\n",
    "if not bm:\n",
    "    bm = get_benchmarker()\n",
    "\n",
    "cz_fidelities = []\n",
    "for edge in graph.edges():\n",
    "    p = Program(CZ(edge[0], edge[1]))\n",
    "    process_exp = generate_process_dfe_experiment(p, bm)\n",
    "    data,cal = acquire_dfe_data(process_exp, qc, desired_variance)\n",
    "    fidelity_est = direct_fidelity_estimate(data,cal,'process')\n",
    "    print(edge, \" : \", fidelity_est.fid_point_est, \"+/-\", np.sqrt(fidelity_est.fid_var_est))\n",
    "    cz_fidelities.append((edge, fidelity_est))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CZ Cross Talk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forest_benchmarking.rpe import (generate_rpe_experiments, \n",
    "                             acquire_rpe_data, \n",
    "                             find_expectation_values, \n",
    "                             robust_phase_estimate)\n",
    "CZ_qubits = (0,1)\n",
    "measure_qubit = 3\n",
    "\n",
    "num_depths = 6\n",
    "multiplicative_factor = 100\n",
    "\n",
    "rpe_experiments = generate_rpe_experiments(Program(CZ(*CZ_qubits)), \n",
    "                                       num_depths, \n",
    "                                       measurement_qubit = measure_qubit)\n",
    "rpe_experiments = acquire_rpe_data(rpe_experiments, qc, multiplicative_factor)\n",
    "xs, ys, x_stds, y_stds = find_expectation_values(rpe_experiments)\n",
    "\n",
    "rz_local_phase_on_qubit = robust_phase_estimate(xs, ys, x_stds, y_stds)\n",
    "print(rz_local_phase_on_qubit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All qubits RX calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = [-pi, -pi/2, pi/2, pi]\n",
    "\n",
    "num_depths = 6 # max depth of 2^(num_depths - 1)\n",
    "factor = 100 # Multiply the optimal number of shots by this factor for each experiment\n",
    "add_error = None # Try to correct for this additivie error by increasing the number of shots in an optimal way\n",
    "\n",
    "for qubit in qubits:\n",
    "    print(\"Q\" + str(qubit))\n",
    "    for angle in angles:\n",
    "        experiments_1q = generate_rpe_experiments(RX(angle, qubit), num_depths, axis=(pi/2,0))\n",
    "        experiments_1q = acquire_rpe_data(experiments_1q, qc, multiplicative_factor = factor, additive_error = add_error)\n",
    "        xs, ys, x_stds, y_stds = find_expectation_values(experiments_1q)\n",
    "        estimated_angle = robust_phase_estimate(xs, ys, x_stds, y_stds)\n",
    "        if angle < 0 and estimated_angle > 0:\n",
    "            estimated_angle = estimated_angle - 2*pi\n",
    "        if angle > 0 and estimated_angle < 0:\n",
    "            estimated_angle = estimated_angle + 2*pi\n",
    "        print(\"Est. Angle:  \", np.round(estimated_angle, 4))\n",
    "        print(\"Ideal Angle: \", np.round(angle, 4))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
